{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasets.live"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIVE\n",
    "\n",
    "> Building a `tf.data.Dataset` for LIVE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import os; os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting up the path to the directory and loading the corresponding `.csv` file, we need to create a generator that will iterate over the dataframe, load and return a 3-tuple: `(Reference Image, Distorted Image, DMOS)`. When can the pass that generator into a `tf.data.Dataset.from_generator()` to build the `Dataset` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LIVE():\n",
    "    \"\"\"Builder for the LIVE dataset\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 path, # Path to the root directory of the dataset\n",
    "                 ):\n",
    "        self.path_root = Path(path) if isinstance(path, str) else path\n",
    "        self.path_ref = self.path_root/\"refimgs\"\n",
    "        self.path_csv = self.path_root/\"image_pairs_dmos.csv\"\n",
    "        self.data = pd.read_csv(self.path_csv, index_col=0)\n",
    "\n",
    "    @property\n",
    "    def dataset(self):\n",
    "        \"\"\"tf.data.Dataset object built from the LIVE dataset.\"\"\"\n",
    "        return tf.data.Dataset.from_generator(\n",
    "                self.data_gen,\n",
    "                output_signature=(\n",
    "                    tf.TensorSpec(shape=(512, 768, 3), dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=(512, 768, 3), dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=(), dtype=tf.float32)\n",
    "                )\n",
    "            ) \n",
    "\n",
    "    def data_gen(self):\n",
    "        \"\"\"Dataset generator to build the tf.data.Dataset.\"\"\"\n",
    "        for i, (ref, dist, dmos) in self.data.iterrows():\n",
    "            dist = cv2.imread(str(self.path_root/dist))\n",
    "            dist = cv2.cvtColor(dist, cv2.COLOR_BGR2RGB)/255.0\n",
    "            ref = cv2.imread(str(self.path_ref/ref))\n",
    "            ref = cv2.cvtColor(ref, cv2.COLOR_BGR2RGB)/255.0\n",
    "            yield ref, dist, dmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LIVE(path = Path(\"/media/disk/databases/BBDD_video_image/Image_Quality/LIVE/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b, c in l.dataset:\n",
    "    break\n",
    "assert a.shape == b.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf26')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
