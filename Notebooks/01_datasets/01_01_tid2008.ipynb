{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasets.tid2008"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TID2008\n",
    "\n",
    "> Building a `tf.data.Dataset` for TID2008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import os; os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting up the path to the directory and loading the corresponding `.csv` file, we need to create a generator that will iterate over the dataframe, load and return a 3-tuple: `(Reference Image, Distorted Image, DMOS)`. Before, we were using a generator to fetch the data but by creating the dataset with only the paths to the images and their mos and mapping the function used to load them, we can obtain massive speed-ups due to the paralelization capabilities being increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TID2008():\n",
    "    \"\"\"Builder for the TID2008 dataset\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 path, # Path to the root directory of the dataset.\n",
    "                 exclude_imgs: List[int] = None, #Â Image ID's to exclude.\n",
    "                 exclude_dist: List[int] = None, # Distortion ID's to exclude.\n",
    "                 exclude_ints: List[int] = None, # Distortion Intensities ID's to exclude.\n",
    "                 num_parallel_calls: int = tf.data.AUTOTUNE, # Number of parallel calls when loading the images.\n",
    "                 ):\n",
    "        self.path_root = Path(path) if isinstance(path, str) else path\n",
    "        self.path_ref = self.path_root/\"reference_images\"\n",
    "        self.path_dist = self.path_root/\"distorted_images\"\n",
    "        self.path_csv = self.path_root/\"image_pairs_mos.csv\"\n",
    "        self.data = self.load_data(self.path_csv, exclude_imgs, exclude_dist, exclude_ints)\n",
    "        self.paths_ref = [str(self.path_ref/p) for p in self.data[\"Reference\"]]\n",
    "        self.paths_dist = [str(self.path_dist/p) for p in self.data[\"Distorted\"]]\n",
    "        self.num_parallel_calls = num_parallel_calls\n",
    "        # self.paths_pair_mos = tf.data.Dataset.from_tensor_slices((self.paths_ref, self.paths_dist, self.data[\"MOS\"]))\n",
    "\n",
    "    @property\n",
    "    def dataset(self):\n",
    "        \"\"\"tf.data.Dataset object built from the TID2008 dataset.\"\"\"\n",
    "        return tf.data.Dataset.from_tensor_slices((self.paths_ref, self.paths_dist, self.data[\"MOS\"]))\\\n",
    "                              .map(self.preprocess, num_parallel_calls=self.num_parallel_calls)\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess(path_ref,\n",
    "                   path_dist,\n",
    "                   mos,\n",
    "                   ):\n",
    "        img_ref = tf.io.read_file(path_ref)\n",
    "        img_dist = tf.io.read_file(path_dist)\n",
    "\n",
    "        img_ref = tf.image.decode_bmp(img_ref, channels=3)\n",
    "        img_dist = tf.image.decode_bmp(img_dist, channels=3)\n",
    "\n",
    "        img_ref = tf.image.convert_image_dtype(img_ref, dtype=tf.float32)\n",
    "        img_dist = tf.image.convert_image_dtype(img_dist, dtype=tf.float32)\n",
    "\n",
    "        return img_ref, img_dist, mos\n",
    "\n",
    "    def data_gen(self):\n",
    "        \"\"\"Dataset generator to build the tf.data.Dataset.\"\"\"\n",
    "        for i, row in self.data.iterrows():\n",
    "            ref, dist, mos = row.Reference, row.Distorted, row.MOS\n",
    "            dist = cv2.imread(str(self.path_dist/dist))\n",
    "            dist = cv2.cvtColor(dist, cv2.COLOR_BGR2RGB)/255.0\n",
    "            ref = cv2.imread(str(self.path_ref/ref))\n",
    "            ref = cv2.cvtColor(ref, cv2.COLOR_BGR2RGB)/255.0\n",
    "            yield ref, dist, mos\n",
    "\n",
    "    def load_data(self,\n",
    "                  path,\n",
    "                  exclude_imgs,\n",
    "                  exclude_dist,\n",
    "                  exclude_ints,\n",
    "                  ):\n",
    "        data = pd.read_csv(self.path_csv, index_col=0)\n",
    "        data = data[~data.Reference_ID.isin(exclude_imgs)] if exclude_imgs is not None else data\n",
    "        data = data[~data.Reference_ID.isin(exclude_dist)] if exclude_dist is not None else data\n",
    "        data = data[~data.Reference_ID.isin(exclude_ints)] if exclude_ints is not None else data\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = TID2008(path = Path(\"/media/disk/databases/BBDD_video_image/Image_Quality/TID/TID2008\"))\n",
    "l = TID2008(path = Path(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA/TID/TID2008/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-13 14:52:07.981337: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-09-13 14:52:07.981424: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mlui02.ific.uv.es\n",
      "2023-09-13 14:52:07.981448: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mlui02.ific.uv.es\n",
      "2023-09-13 14:52:07.981611: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.54.3\n",
      "2023-09-13 14:52:07.981683: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.54.3\n",
      "2023-09-13 14:52:07.981698: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 535.54.3\n",
      "2023-09-13 14:52:07.983199: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "for a, b, c in l.dataset:\n",
    "    break\n",
    "assert a.shape == b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can benchmark it to finish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956b11d0f4f04c2bb77313c4e4dfaf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "from tqdm.auto import tqdm\n",
    "for a, b, c in tqdm(l.dataset): pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
