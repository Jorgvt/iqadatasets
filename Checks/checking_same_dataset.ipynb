{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking if the datasets are equivalent to the others we have been using before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "from glob import glob\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "from iqadatasets.datasets.tid2013 import TID2013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_2008(img_ids='all', \n",
    "                dist_ids='all',\n",
    "                dist_ints='all',\n",
    "                exclude_img_ids=None,\n",
    "                exclude_dist_ids=None,\n",
    "                exclude_dist_ints=None):\n",
    "    \"\"\"\n",
    "    Filters the data to only utilize a subset based on img_id.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_ids: list[string]\n",
    "        List of image IDs to use passed as strings.\n",
    "    dist_ids: list[string]\n",
    "        List of image IDs to use passed as strings.\n",
    "    dist_int: list[string]\n",
    "        List of image IDs to use passed as strings.\n",
    "        As of now, the intensities go from 1 to 5.\n",
    "    exclude_img_ids: list[string]\n",
    "        List of image IDs to exclude passed as strings.\n",
    "    exclude_dist_ids: list[string]\n",
    "        List of image IDs to exclude passed as strings.\n",
    "    exclude_dist_int: list[string]\n",
    "        List of image IDs to exclude passed as strings.\n",
    "        As of now, the intensities go from 1 to 5.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data: list[ImagePair]\n",
    "        List of ImagePair objects containing the paths to the image pairs and \n",
    "        their corresponding metric.\n",
    "    \"\"\"\n",
    "    ## It's not good practice to default a parameter as an empty list.\n",
    "    ## The good practice is to default it as a None and then create the empty list.\n",
    "    exclude_img_ids = [] if exclude_img_ids == None else exclude_img_ids\n",
    "    exclude_dist_ids = [] if exclude_dist_ids == None else exclude_dist_ids\n",
    "    exclude_dist_ints = [] if exclude_dist_ints == None else exclude_dist_ints\n",
    "    data = []\n",
    "    for img_path in glob(os.path.join(path_2008, 'reference_images', '*.BMP')):\n",
    "        if img_ids != 'all': # We only want to skip images if any ids were specified\n",
    "            if img_path.lower().split(\"/\")[-1].split(\".\")[0][1:] not in img_ids:\n",
    "                continue # Skips this loop iteration if the ids is not being selected\n",
    "        elif len(exclude_img_ids)>0:\n",
    "            if img_path.lower().split(\"/\")[-1].split(\".\")[0][1:] in exclude_img_ids:\n",
    "                continue\n",
    "        for dist_img_path in glob(os.path.join(path_2008, 'distorted_images', f'{img_path.split(\"/\")[-1].split(\".\")[0]}*')):\n",
    "            dist_id, dist_int = dist_img_path.lower().split(\"/\")[-1].split(\".\")[0][1:].split(\"_\")[1:]\n",
    "            \n",
    "            if dist_ids!='all':\n",
    "                if dist_id not in dist_ids:\n",
    "                    continue\n",
    "            elif len(exclude_dist_ids)>0:\n",
    "                if dist_id in exclude_dist_ids:\n",
    "                    continue\n",
    "            if dist_ints!='all':\n",
    "                if dist_int not in dist_ints:\n",
    "                    continue\n",
    "            elif len(exclude_dist_ints)>0:\n",
    "                if dist_int in exclude_dist_ints:\n",
    "                    continue\n",
    "            \n",
    "            data.append(ImagePair(img_path, dist_img_path, name_metric_2008[dist_img_path.split(\"/\")[-1].split(\".\")[0]]))\n",
    "    return data\n",
    "\n",
    "def filter_data_2013(img_ids='all', \n",
    "                dist_ids='all',\n",
    "                dist_ints='all',\n",
    "                exclude_img_ids=None,\n",
    "                exclude_dist_ids=None,\n",
    "                exclude_dist_ints=None):\n",
    "    \"\"\"\n",
    "    Filters the data to only utilize a subset based on img_id.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_ids: list[string]\n",
    "        List of image IDs to use passed as strings.\n",
    "    dist_ids: list[string]\n",
    "        List of image IDs to use passed as strings.\n",
    "    dist_int: list[string]\n",
    "        List of image IDs to use passed as strings.\n",
    "        As of now, the intensities go from 1 to 5.\n",
    "    exclude_img_ids: list[string]\n",
    "        List of image IDs to exclude passed as strings.\n",
    "    exclude_dist_ids: list[string]\n",
    "        List of image IDs to exclude passed as strings.\n",
    "    exclude_dist_int: list[string]\n",
    "        List of image IDs to exclude passed as strings.\n",
    "        As of now, the intensities go from 1 to 5.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data: list[ImagePair]\n",
    "        List of ImagePair objects containing the paths to the image pairs and \n",
    "        their corresponding metric.\n",
    "    \"\"\"\n",
    "    ## It's not good practice to default a parameter as an empty list.\n",
    "    ## The good practice is to default it as a None and then create the empty list.\n",
    "    exclude_img_ids = [] if exclude_img_ids == None else exclude_img_ids\n",
    "    exclude_dist_ids = [] if exclude_dist_ids == None else exclude_dist_ids\n",
    "    exclude_dist_ints = [] if exclude_dist_ints == None else exclude_dist_ints\n",
    "    data = []\n",
    "    for img_path in glob(os.path.join(path_2013, 'reference_images', '*.BMP')):\n",
    "        if img_ids != 'all': # We only want to skip images if any ids were specified\n",
    "            if img_path.lower().split(\"/\")[-1].split(\".\")[0][1:] not in img_ids:\n",
    "                continue # Skips this loop iteration if the ids is not being selected\n",
    "        elif len(exclude_img_ids)>0:\n",
    "            if img_path.lower().split(\"/\")[-1].split(\".\")[0][1:] in exclude_img_ids:\n",
    "                continue\n",
    "        for dist_img_path in glob(os.path.join(path_2013, 'distorted_images', f'{img_path.lower().split(\"/\")[-1].split(\".\")[0]}*')):\n",
    "            dist_id, dist_int = dist_img_path.lower().split(\"/\")[-1].split(\".\")[0][1:].split(\"_\")[1:]\n",
    "            \n",
    "            if dist_ids!='all':\n",
    "                if dist_id not in dist_ids:\n",
    "                    continue\n",
    "            elif len(exclude_dist_ids)>0:\n",
    "                if dist_id in exclude_dist_ids:\n",
    "                    continue\n",
    "            if dist_ints!='all':\n",
    "                if dist_int not in dist_ints:\n",
    "                    continue\n",
    "            elif len(exclude_dist_ints)>0:\n",
    "                if dist_int in exclude_dist_ints:\n",
    "                    continue\n",
    "            \n",
    "            data.append(ImagePair(img_path, dist_img_path, name_metric_2013[dist_img_path.split(\"/\")[-1].split(\".\")[0]]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_2008 = '/media/disk/databases/BBDD_video_image/Image_Quality/TID/TID2008'\n",
    "path_2013 = '/media/disk/databases/BBDD_video_image/Image_Quality/TID/TID2013'\n",
    "\n",
    "name_metric_2008 = {}\n",
    "with open(os.path.join(path_2008, 'mos_with_names.txt')) as f:\n",
    "    for line in f.readlines():\n",
    "        # remove last character to avoid \\n\n",
    "        metric, file_name = line[:-1].split(\" \")\n",
    "        name_metric_2008[file_name.upper().split(\".\")[0]] = float(metric)\n",
    "\n",
    "name_metric_2013 = {}\n",
    "with open(os.path.join(path_2013, 'mos_with_names.txt')) as f:\n",
    "    for line in f.readlines():\n",
    "        # remove last character to avoid \\n\n",
    "        metric, file_name = line[:-1].split(\" \")\n",
    "        name_metric_2013[file_name.lower().split(\".\")[0]] = float(metric)\n",
    "\n",
    "ImagePair = namedtuple('ImagePair', 'img_path dist_img_path metric')\n",
    "\n",
    "train_data = filter_data_2008(img_ids='all',\n",
    "                            dist_ids='all',\n",
    "                            dist_ints='all',\n",
    "                            exclude_img_ids=['25'],\n",
    "                    )\n",
    "test_data = filter_data_2013(img_ids='all',\n",
    "                        dist_ids='all',\n",
    "                        dist_ints='all',\n",
    "                        exclude_img_ids=['25'],\n",
    "                    )\n",
    "\n",
    "def train_gen():\n",
    "    for sample in train_data:\n",
    "        img = cv2.imread(sample.img_path)\n",
    "        dist_img = cv2.imread(sample.dist_img_path)\n",
    "        if True:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            dist_img = cv2.cvtColor(dist_img, cv2.COLOR_BGR2RGB)\n",
    "        img = img/255.0\n",
    "        dist_img = dist_img/255.0\n",
    "        metric = sample.metric\n",
    "        yield img, dist_img, metric\n",
    "\n",
    "def test_gen():\n",
    "    for sample in test_data:\n",
    "        img = cv2.imread(sample.img_path)\n",
    "        dist_img = cv2.imread(sample.dist_img_path)\n",
    "        if True:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            dist_img = cv2.cvtColor(dist_img, cv2.COLOR_BGR2RGB)\n",
    "        img = img/255.0\n",
    "        dist_img = dist_img/255.0\n",
    "        metric = sample.metric\n",
    "        yield img, dist_img, metric\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(train_gen,\n",
    "                                                output_signature=(\n",
    "                                                    tf.TensorSpec(shape=(384, 512, 3), dtype=tf.float32),\n",
    "                                                    tf.TensorSpec(shape=(384, 512, 3), dtype=tf.float32),\n",
    "                                                    tf.TensorSpec(shape=(), dtype=tf.float32)\n",
    "                                                ))\n",
    "test_dataset = tf.data.Dataset.from_generator(test_gen,\n",
    "                                                output_signature=(\n",
    "                                                    tf.TensorSpec(shape=(384, 512, 3), dtype=tf.float32),\n",
    "                                                    tf.TensorSpec(shape=(384, 512, 3), dtype=tf.float32),\n",
    "                                                    tf.TensorSpec(shape=(), dtype=tf.float32)\n",
    "                                                ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<FlatMapDataset shapes: ((384, 512, 3), (384, 512, 3), ()), types: (tf.float32, tf.float32, tf.float32)>,\n",
       " <FlatMapDataset shapes: ((384, 512, 3), (384, 512, 3), ()), types: (tf.float32, tf.float32, tf.float32)>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = TID2013(\"/media/disk/databases/BBDD_video_image/Image_Quality/TID/TID2013\", exclude_imgs=[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, _ in enumerate(test_dataset):pass\n",
    "for j, _ in enumerate(l.dataset):pass\n",
    "assert i==j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if every element of the new dataset is in the old dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastprogress.fastprogress import progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matches = 0\n",
    "# for new in progress_bar(l.dataset, total=2880):\n",
    "#     for old in test_dataset:\n",
    "#         if (new[0].numpy()==old[0].numpy()).all() & (new[1].numpy()==old[1].numpy()).all() & (new[2]==old[2]): \n",
    "#             matches += 1\n",
    "#             break\n",
    "#         else: continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf26')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e5e7d3ec6da8cae83531001485d926ded04fa3b6e3dfe28c110c78c0ec74159"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
